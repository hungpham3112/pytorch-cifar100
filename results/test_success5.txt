/home/the-hung/miniforge3/envs/cinnamon/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
CustomSEResNet(
  (pre): Sequential(
    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (stage1): Sequential(
    (0): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=64, out_features=2, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=2, out_features=64, bias=True)
        (4): Sigmoid()
      )
    )
    (1): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=64, out_features=2, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=2, out_features=64, bias=True)
        (4): Sigmoid()
      )
    )
    (2): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=64, out_features=2, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=2, out_features=64, bias=True)
        (4): Sigmoid()
      )
    )
  )
  (stage2): Sequential(
    (0): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=128, out_features=4, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4, out_features=128, bias=True)
        (4): Sigmoid()
      )
    )
    (1): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=128, out_features=4, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4, out_features=128, bias=True)
        (4): Sigmoid()
      )
    )
    (2): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=128, out_features=4, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4, out_features=128, bias=True)
        (4): Sigmoid()
      )
    )
    (3): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=128, out_features=4, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4, out_features=128, bias=True)
        (4): Sigmoid()
      )
    )
  )
  (stage3): Sequential(
    (0): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=256, out_features=8, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=8, out_features=256, bias=True)
        (4): Sigmoid()
      )
    )
    (1): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=256, out_features=8, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=8, out_features=256, bias=True)
        (4): Sigmoid()
      )
    )
    (2): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=256, out_features=8, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=8, out_features=256, bias=True)
        (4): Sigmoid()
      )
    )
    (3): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=256, out_features=8, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=8, out_features=256, bias=True)
        (4): Sigmoid()
      )
    )
    (4): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=256, out_features=8, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=8, out_features=256, bias=True)
        (4): Sigmoid()
      )
    )
    (5): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=256, out_features=8, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=8, out_features=256, bias=True)
        (4): Sigmoid()
      )
    )
  )
  (stage4): Sequential(
    (0): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=512, out_features=16, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=16, out_features=512, bias=True)
        (4): Sigmoid()
      )
    )
    (1): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=512, out_features=16, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=16, out_features=512, bias=True)
        (4): Sigmoid()
      )
    )
    (2): CustomBasicResidualSEBlock(
      (residual): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (shortcut): Sequential()
      (squeeze): AdaptiveAvgPool2d(output_size=1)
      (excitation): Sequential(
        (0): Linear(in_features=512, out_features=16, bias=True)
        (1): SiLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=16, out_features=512, bias=True)
        (4): Sigmoid()
      )
    )
  )
  (linear1): Linear(in_features=512, out_features=952, bias=True)
)
Evaluating:   0%|          | 0/687 [00:00<?, ?batch/s]Evaluating:   0%|          | 1/687 [00:01<16:31,  1.45s/batch]Evaluating:   0%|          | 3/687 [00:01<04:45,  2.39batch/s]Evaluating:   1%|          | 5/687 [00:01<02:38,  4.30batch/s]Evaluating:   1%|          | 7/687 [00:01<01:48,  6.29batch/s]Evaluating:   1%|▏         | 9/687 [00:01<01:21,  8.30batch/s]Evaluating:   2%|▏         | 11/687 [00:02<01:06, 10.14batch/s]Evaluating:   2%|▏         | 13/687 [00:02<00:57, 11.75batch/s]Evaluating:   2%|▏         | 15/687 [00:02<00:51, 13.07batch/s]Evaluating:   2%|▏         | 17/687 [00:02<00:47, 14.20batch/s]Evaluating:   3%|▎         | 19/687 [00:02<00:44, 15.03batch/s]Evaluating:   3%|▎         | 21/687 [00:02<00:42, 15.54batch/s]Evaluating:   3%|▎         | 23/687 [00:02<00:41, 16.08batch/s]Evaluating:   4%|▎         | 25/687 [00:02<00:40, 16.50batch/s]Evaluating:   4%|▍         | 27/687 [00:02<00:39, 16.51batch/s]Evaluating:   4%|▍         | 29/687 [00:03<00:40, 16.39batch/s]Evaluating:   5%|▍         | 31/687 [00:03<00:40, 16.36batch/s]Evaluating:   5%|▍         | 33/687 [00:03<00:39, 16.56batch/s]Evaluating:   5%|▌         | 35/687 [00:03<00:38, 16.81batch/s]Evaluating:   5%|▌         | 37/687 [00:03<00:38, 17.02batch/s]Evaluating:   6%|▌         | 39/687 [00:03<00:37, 17.15batch/s]Evaluating:   6%|▌         | 41/687 [00:03<00:37, 17.23batch/s]Evaluating:   6%|▋         | 43/687 [00:03<00:37, 17.31batch/s]Evaluating:   7%|▋         | 45/687 [00:04<00:36, 17.36batch/s]Evaluating:   7%|▋         | 47/687 [00:04<00:36, 17.41batch/s]Evaluating:   7%|▋         | 49/687 [00:04<00:36, 17.46batch/s]Evaluating:   7%|▋         | 51/687 [00:04<00:36, 17.47batch/s]Evaluating:   8%|▊         | 53/687 [00:04<00:36, 17.49batch/s]Evaluating:   8%|▊         | 55/687 [00:04<00:36, 17.49batch/s]Evaluating:   8%|▊         | 57/687 [00:04<00:36, 17.48batch/s]Evaluating:   9%|▊         | 59/687 [00:04<00:35, 17.51batch/s]Evaluating:   9%|▉         | 61/687 [00:04<00:35, 17.51batch/s]Evaluating:   9%|▉         | 63/687 [00:05<00:35, 17.49batch/s]Evaluating:   9%|▉         | 65/687 [00:05<00:35, 17.45batch/s]Evaluating:  10%|▉         | 67/687 [00:05<00:35, 17.39batch/s]Evaluating:  10%|█         | 69/687 [00:05<00:35, 17.36batch/s]Evaluating:  10%|█         | 71/687 [00:05<00:35, 17.36batch/s]Evaluating:  11%|█         | 73/687 [00:05<00:35, 17.34batch/s]Evaluating:  11%|█         | 75/687 [00:05<00:35, 17.31batch/s]Evaluating:  11%|█         | 77/687 [00:05<00:35, 17.30batch/s]Evaluating:  11%|█▏        | 79/687 [00:05<00:35, 17.30batch/s]Evaluating:  12%|█▏        | 81/687 [00:06<00:35, 17.27batch/s]Evaluating:  12%|█▏        | 83/687 [00:06<00:35, 17.24batch/s]Evaluating:  12%|█▏        | 85/687 [00:06<00:34, 17.27batch/s]Evaluating:  13%|█▎        | 87/687 [00:06<00:34, 17.28batch/s]Evaluating:  13%|█▎        | 89/687 [00:06<00:34, 17.28batch/s]Evaluating:  13%|█▎        | 91/687 [00:06<00:34, 17.29batch/s]Evaluating:  14%|█▎        | 93/687 [00:06<00:34, 17.29batch/s]Evaluating:  14%|█▍        | 95/687 [00:06<00:34, 17.30batch/s]Evaluating:  14%|█▍        | 97/687 [00:07<00:34, 17.29batch/s]Evaluating:  14%|█▍        | 99/687 [00:07<00:33, 17.30batch/s]Evaluating:  15%|█▍        | 101/687 [00:07<00:33, 17.30batch/s]Evaluating:  15%|█▍        | 103/687 [00:07<00:33, 17.27batch/s]Evaluating:  15%|█▌        | 105/687 [00:07<00:33, 17.27batch/s]Evaluating:  16%|█▌        | 107/687 [00:07<00:33, 17.28batch/s]Evaluating:  16%|█▌        | 109/687 [00:07<00:33, 17.29batch/s]Evaluating:  16%|█▌        | 111/687 [00:07<00:33, 17.26batch/s]Evaluating:  16%|█▋        | 113/687 [00:07<00:33, 17.29batch/s]Evaluating:  17%|█▋        | 115/687 [00:08<00:33, 17.29batch/s]Evaluating:  17%|█▋        | 117/687 [00:08<00:33, 17.26batch/s]Evaluating:  17%|█▋        | 119/687 [00:08<00:32, 17.28batch/s]Evaluating:  18%|█▊        | 121/687 [00:08<00:32, 17.29batch/s]Evaluating:  18%|█▊        | 123/687 [00:08<00:32, 17.23batch/s]Evaluating:  18%|█▊        | 125/687 [00:08<00:32, 17.27batch/s]Evaluating:  18%|█▊        | 127/687 [00:08<00:32, 17.29batch/s]Evaluating:  19%|█▉        | 129/687 [00:08<00:32, 17.27batch/s]Evaluating:  19%|█▉        | 131/687 [00:08<00:32, 17.27batch/s]Evaluating:  19%|█▉        | 133/687 [00:09<00:32, 17.28batch/s]Evaluating:  20%|█▉        | 135/687 [00:09<00:31, 17.29batch/s]Evaluating:  20%|█▉        | 137/687 [00:09<00:31, 17.28batch/s]Evaluating:  20%|██        | 139/687 [00:09<00:31, 17.25batch/s]Evaluating:  21%|██        | 141/687 [00:09<00:31, 17.28batch/s]Evaluating:  21%|██        | 143/687 [00:09<00:31, 17.28batch/s]Evaluating:  21%|██        | 145/687 [00:09<00:31, 17.25batch/s]Evaluating:  21%|██▏       | 147/687 [00:09<00:31, 17.25batch/s]Evaluating:  22%|██▏       | 149/687 [00:10<00:31, 17.27batch/s]Evaluating:  22%|██▏       | 151/687 [00:10<00:31, 17.25batch/s]Evaluating:  22%|██▏       | 153/687 [00:10<00:30, 17.26batch/s]Evaluating:  23%|██▎       | 155/687 [00:10<00:30, 17.30batch/s]Evaluating:  23%|██▎       | 157/687 [00:10<00:30, 17.29batch/s]Evaluating:  23%|██▎       | 159/687 [00:10<00:30, 17.26batch/s]Evaluating:  23%|██▎       | 161/687 [00:10<00:30, 17.28batch/s]Evaluating:  24%|██▎       | 163/687 [00:10<00:30, 17.29batch/s]Evaluating:  24%|██▍       | 165/687 [00:10<00:30, 17.27batch/s]Evaluating:  24%|██▍       | 167/687 [00:11<00:30, 17.24batch/s]Evaluating:  25%|██▍       | 169/687 [00:11<00:29, 17.28batch/s]Evaluating:  25%|██▍       | 171/687 [00:11<00:29, 17.27batch/s]Evaluating:  25%|██▌       | 173/687 [00:11<00:29, 17.26batch/s]Evaluating:  25%|██▌       | 175/687 [00:11<00:29, 17.25batch/s]Evaluating:  26%|██▌       | 177/687 [00:11<00:29, 17.28batch/s]Evaluating:  26%|██▌       | 179/687 [00:11<00:29, 17.09batch/s]Evaluating:  26%|██▋       | 181/687 [00:11<00:29, 16.94batch/s]Evaluating:  27%|██▋       | 183/687 [00:11<00:29, 17.03batch/s]Evaluating:  27%|██▋       | 185/687 [00:12<00:29, 17.10batch/s]Evaluating:  27%|██▋       | 187/687 [00:12<00:29, 17.17batch/s]Evaluating:  28%|██▊       | 189/687 [00:12<00:29, 17.17batch/s]Evaluating:  28%|██▊       | 191/687 [00:12<00:28, 17.17batch/s]Evaluating:  28%|██▊       | 193/687 [00:12<00:28, 17.21batch/s]Evaluating:  28%|██▊       | 195/687 [00:12<00:28, 17.24batch/s]Evaluating:  29%|██▊       | 197/687 [00:12<00:28, 17.26batch/s]Evaluating:  29%|██▉       | 199/687 [00:12<00:28, 17.25batch/s]Evaluating:  29%|██▉       | 201/687 [00:13<00:28, 17.27batch/s]Evaluating:  30%|██▉       | 203/687 [00:13<00:28, 17.27batch/s]Evaluating:  30%|██▉       | 205/687 [00:13<00:27, 17.27batch/s]Evaluating:  30%|███       | 207/687 [00:13<00:27, 17.23batch/s]Evaluating:  30%|███       | 209/687 [00:13<00:27, 17.25batch/s]Evaluating:  31%|███       | 211/687 [00:13<00:27, 17.20batch/s]Evaluating:  31%|███       | 213/687 [00:13<00:27, 17.22batch/s]Evaluating:  31%|███▏      | 215/687 [00:13<00:27, 17.22batch/s]Evaluating:  32%|███▏      | 217/687 [00:13<00:27, 17.24batch/s]Evaluating:  32%|███▏      | 219/687 [00:14<00:27, 17.24batch/s]Evaluating:  32%|███▏      | 221/687 [00:14<00:27, 17.20batch/s]Evaluating:  32%|███▏      | 223/687 [00:14<00:26, 17.20batch/s]Evaluating:  33%|███▎      | 225/687 [00:14<00:26, 17.23batch/s]Evaluating:  33%|███▎      | 227/687 [00:14<00:26, 17.23batch/s]Evaluating:  33%|███▎      | 229/687 [00:14<00:26, 17.22batch/s]Evaluating:  34%|███▎      | 231/687 [00:14<00:26, 17.25batch/s]Evaluating:  34%|███▍      | 233/687 [00:14<00:26, 17.26batch/s]Evaluating:  34%|███▍      | 235/687 [00:15<00:26, 17.25batch/s]Evaluating:  34%|███▍      | 237/687 [00:15<00:26, 17.22batch/s]Evaluating:  35%|███▍      | 239/687 [00:15<00:25, 17.26batch/s]Evaluating:  35%|███▌      | 241/687 [00:15<00:25, 17.26batch/s]Evaluating:  35%|███▌      | 243/687 [00:15<00:25, 17.24batch/s]Evaluating:  36%|███▌      | 245/687 [00:15<00:25, 17.24batch/s]Evaluating:  36%|███▌      | 247/687 [00:15<00:25, 17.25batch/s]Evaluating:  36%|███▌      | 249/687 [00:15<00:25, 17.23batch/s]Evaluating:  37%|███▋      | 251/687 [00:15<00:25, 17.22batch/s]Evaluating:  37%|███▋      | 253/687 [00:16<00:25, 17.24batch/s]Evaluating:  37%|███▋      | 255/687 [00:16<00:25, 17.27batch/s]Evaluating:  37%|███▋      | 257/687 [00:16<00:24, 17.25batch/s]Evaluating:  38%|███▊      | 259/687 [00:16<00:24, 17.26batch/s]Evaluating:  38%|███▊      | 261/687 [00:16<00:24, 17.27batch/s]Evaluating:  38%|███▊      | 263/687 [00:16<00:24, 17.27batch/s]Evaluating:  39%|███▊      | 265/687 [00:16<00:24, 17.27batch/s]Evaluating:  39%|███▉      | 267/687 [00:16<00:24, 17.29batch/s]Evaluating:  39%|███▉      | 269/687 [00:16<00:24, 17.29batch/s]Evaluating:  39%|███▉      | 271/687 [00:17<00:24, 17.28batch/s]Evaluating:  40%|███▉      | 273/687 [00:17<00:23, 17.25batch/s]Evaluating:  40%|████      | 275/687 [00:17<00:23, 17.27batch/s]Evaluating:  40%|████      | 277/687 [00:17<00:23, 17.26batch/s]Evaluating:  41%|████      | 279/687 [00:17<00:23, 17.23batch/s]Evaluating:  41%|████      | 281/687 [00:17<00:23, 17.21batch/s]Evaluating:  41%|████      | 283/687 [00:17<00:23, 17.24batch/s]Evaluating:  41%|████▏     | 285/687 [00:17<00:23, 17.25batch/s]Evaluating:  42%|████▏     | 287/687 [00:18<00:23, 17.24batch/s]Evaluating:  42%|████▏     | 289/687 [00:18<00:23, 17.24batch/s]Evaluating:  42%|████▏     | 291/687 [00:18<00:22, 17.24batch/s]Evaluating:  43%|████▎     | 293/687 [00:18<00:22, 17.24batch/s]Evaluating:  43%|████▎     | 295/687 [00:18<00:22, 17.22batch/s]Evaluating:  43%|████▎     | 297/687 [00:18<00:22, 17.21batch/s]Evaluating:  44%|████▎     | 299/687 [00:18<00:22, 17.21batch/s]Evaluating:  44%|████▍     | 301/687 [00:18<00:22, 17.19batch/s]Evaluating:  44%|████▍     | 303/687 [00:18<00:22, 17.18batch/s]Evaluating:  44%|████▍     | 305/687 [00:19<00:22, 17.18batch/s]Evaluating:  45%|████▍     | 307/687 [00:19<00:22, 17.20batch/s]Evaluating:  45%|████▍     | 309/687 [00:19<00:21, 17.20batch/s]Evaluating:  45%|████▌     | 311/687 [00:19<00:21, 17.20batch/s]Evaluating:  46%|████▌     | 313/687 [00:19<00:21, 17.23batch/s]Evaluating:  46%|████▌     | 315/687 [00:19<00:21, 17.25batch/s]Evaluating:  46%|████▌     | 317/687 [00:19<00:21, 17.24batch/s]Evaluating:  46%|████▋     | 319/687 [00:19<00:21, 17.22batch/s]Evaluating:  47%|████▋     | 321/687 [00:19<00:21, 17.25batch/s]Evaluating:  47%|████▋     | 323/687 [00:20<00:21, 17.25batch/s]Evaluating:  47%|████▋     | 325/687 [00:20<00:21, 17.23batch/s]Evaluating:  48%|████▊     | 327/687 [00:20<00:20, 17.23batch/s]Evaluating:  48%|████▊     | 329/687 [00:20<00:20, 17.27batch/s]Evaluating:  48%|████▊     | 331/687 [00:20<00:20, 17.26batch/s]Evaluating:  48%|████▊     | 333/687 [00:20<00:20, 17.21batch/s]Evaluating:  49%|████▉     | 335/687 [00:20<00:20, 17.24batch/s]Evaluating:  49%|████▉     | 337/687 [00:20<00:20, 17.24batch/s]Evaluating:  49%|████▉     | 339/687 [00:21<00:20, 17.23batch/s]Evaluating:  50%|████▉     | 341/687 [00:21<00:20, 17.22batch/s]Evaluating:  50%|████▉     | 343/687 [00:21<00:19, 17.25batch/s]Evaluating:  50%|█████     | 345/687 [00:21<00:19, 17.26batch/s]Evaluating:  51%|█████     | 347/687 [00:21<00:19, 17.26batch/s]Evaluating:  51%|█████     | 349/687 [00:21<00:19, 17.25batch/s]Evaluating:  51%|█████     | 351/687 [00:21<00:19, 17.28batch/s]Evaluating:  51%|█████▏    | 353/687 [00:21<00:19, 17.29batch/s]Evaluating:  52%|█████▏    | 355/687 [00:21<00:19, 17.26batch/s]Evaluating:  52%|█████▏    | 357/687 [00:22<00:19, 17.25batch/s]Evaluating:  52%|█████▏    | 359/687 [00:22<00:19, 17.24batch/s]Evaluating:  53%|█████▎    | 361/687 [00:22<00:18, 17.25batch/s]Evaluating:  53%|█████▎    | 363/687 [00:22<00:18, 17.22batch/s]Evaluating:  53%|█████▎    | 365/687 [00:22<00:18, 17.24batch/s]Evaluating:  53%|█████▎    | 367/687 [00:22<00:18, 17.26batch/s]Evaluating:  54%|█████▎    | 369/687 [00:22<00:18, 17.24batch/s]Evaluating:  54%|█████▍    | 371/687 [00:22<00:18, 17.20batch/s]Evaluating:  54%|█████▍    | 373/687 [00:23<00:18, 17.22batch/s]Evaluating:  55%|█████▍    | 375/687 [00:23<00:18, 17.22batch/s]Evaluating:  55%|█████▍    | 377/687 [00:23<00:18, 17.21batch/s]Evaluating:  55%|█████▌    | 379/687 [00:23<00:17, 17.18batch/s]Evaluating:  55%|█████▌    | 381/687 [00:23<00:17, 17.19batch/s]Evaluating:  56%|█████▌    | 383/687 [00:23<00:17, 17.19batch/s]Evaluating:  56%|█████▌    | 385/687 [00:23<00:17, 17.17batch/s]Evaluating:  56%|█████▋    | 387/687 [00:23<00:17, 17.18batch/s]Evaluating:  57%|█████▋    | 389/687 [00:23<00:17, 17.22batch/s]Evaluating:  57%|█████▋    | 391/687 [00:24<00:17, 17.23batch/s]Evaluating:  57%|█████▋    | 393/687 [00:24<00:17, 17.23batch/s]Evaluating:  57%|█████▋    | 395/687 [00:24<00:16, 17.22batch/s]Evaluating:  58%|█████▊    | 397/687 [00:24<00:16, 17.23batch/s]Evaluating:  58%|█████▊    | 399/687 [00:24<00:16, 17.24batch/s]Evaluating:  58%|█████▊    | 401/687 [00:24<00:16, 17.22batch/s]Evaluating:  59%|█████▊    | 403/687 [00:24<00:16, 17.19batch/s]Evaluating:  59%|█████▉    | 405/687 [00:24<00:16, 17.24batch/s]Evaluating:  59%|█████▉    | 407/687 [00:24<00:16, 17.24batch/s]Evaluating:  60%|█████▉    | 409/687 [00:25<00:16, 17.22batch/s]Evaluating:  60%|█████▉    | 411/687 [00:25<00:16, 17.22batch/s]Evaluating:  60%|██████    | 413/687 [00:25<00:15, 17.24batch/s]Evaluating:  60%|██████    | 415/687 [00:25<00:15, 17.22batch/s]Evaluating:  61%|██████    | 417/687 [00:25<00:15, 17.24batch/s]Evaluating:  61%|██████    | 419/687 [00:25<00:15, 17.24batch/s]Evaluating:  61%|██████▏   | 421/687 [00:25<00:15, 17.24batch/s]Evaluating:  62%|██████▏   | 423/687 [00:25<00:15, 17.24batch/s]Evaluating:  62%|██████▏   | 425/687 [00:26<00:15, 17.20batch/s]Evaluating:  62%|██████▏   | 427/687 [00:26<00:15, 17.22batch/s]Evaluating:  62%|██████▏   | 429/687 [00:26<00:14, 17.23batch/s]Evaluating:  63%|██████▎   | 431/687 [00:26<00:14, 17.26batch/s]Evaluating:  63%|██████▎   | 433/687 [00:26<00:14, 17.28batch/s]Evaluating:  63%|██████▎   | 435/687 [00:26<00:14, 17.28batch/s]Evaluating:  64%|██████▎   | 437/687 [00:26<00:14, 17.23batch/s]Evaluating:  64%|██████▍   | 439/687 [00:26<00:14, 17.23batch/s]Evaluating:  64%|██████▍   | 441/687 [00:26<00:14, 17.24batch/s]Evaluating:  64%|██████▍   | 443/687 [00:27<00:14, 17.22batch/s]Evaluating:  65%|██████▍   | 445/687 [00:27<00:14, 17.21batch/s]Evaluating:  65%|██████▌   | 447/687 [00:27<00:13, 17.21batch/s]Evaluating:  65%|██████▌   | 449/687 [00:27<00:13, 17.22batch/s]Evaluating:  66%|██████▌   | 451/687 [00:27<00:13, 17.22batch/s]Evaluating:  66%|██████▌   | 453/687 [00:27<00:13, 17.19batch/s]Evaluating:  66%|██████▌   | 455/687 [00:27<00:13, 17.22batch/s]Evaluating:  67%|██████▋   | 457/687 [00:27<00:13, 17.24batch/s]Evaluating:  67%|██████▋   | 459/687 [00:28<00:13, 17.24batch/s]Evaluating:  67%|██████▋   | 461/687 [00:28<00:13, 17.20batch/s]Evaluating:  67%|██████▋   | 463/687 [00:28<00:13, 17.20batch/s]Evaluating:  68%|██████▊   | 465/687 [00:28<00:12, 17.21batch/s]Evaluating:  68%|██████▊   | 467/687 [00:28<00:12, 17.20batch/s]Evaluating:  68%|██████▊   | 469/687 [00:28<00:12, 17.16batch/s]Evaluating:  69%|██████▊   | 471/687 [00:28<00:12, 17.16batch/s]Evaluating:  69%|██████▉   | 473/687 [00:28<00:12, 17.18batch/s]Evaluating:  69%|██████▉   | 475/687 [00:28<00:12, 17.19batch/s]Evaluating:  69%|██████▉   | 477/687 [00:29<00:12, 17.19batch/s]Evaluating:  70%|██████▉   | 479/687 [00:29<00:12, 17.16batch/s]Evaluating:  70%|███████   | 481/687 [00:29<00:11, 17.17batch/s]Evaluating:  70%|███████   | 483/687 [00:29<00:11, 17.21batch/s]Evaluating:  71%|███████   | 485/687 [00:29<00:11, 17.19batch/s]Evaluating:  71%|███████   | 487/687 [00:29<00:11, 17.21batch/s]Evaluating:  71%|███████   | 489/687 [00:29<00:11, 17.21batch/s]Evaluating:  71%|███████▏  | 491/687 [00:29<00:11, 17.19batch/s]Evaluating:  72%|███████▏  | 493/687 [00:29<00:11, 17.21batch/s]Evaluating:  72%|███████▏  | 495/687 [00:30<00:11, 17.23batch/s]Evaluating:  72%|███████▏  | 497/687 [00:30<00:11, 17.24batch/s]Evaluating:  73%|███████▎  | 499/687 [00:30<00:10, 17.20batch/s]Evaluating:  73%|███████▎  | 501/687 [00:30<00:10, 17.19batch/s]Evaluating:  73%|███████▎  | 503/687 [00:30<00:10, 17.21batch/s]Evaluating:  74%|███████▎  | 505/687 [00:30<00:10, 17.21batch/s]Evaluating:  74%|███████▍  | 507/687 [00:30<00:10, 17.20batch/s]Evaluating:  74%|███████▍  | 509/687 [00:30<00:10, 17.21batch/s]Evaluating:  74%|███████▍  | 511/687 [00:31<00:10, 17.23batch/s]Evaluating:  75%|███████▍  | 513/687 [00:31<00:10, 17.21batch/s]Evaluating:  75%|███████▍  | 515/687 [00:31<00:10, 17.16batch/s]Evaluating:  75%|███████▌  | 517/687 [00:31<00:09, 17.14batch/s]Evaluating:  76%|███████▌  | 519/687 [00:31<00:09, 17.17batch/s]Evaluating:  76%|███████▌  | 521/687 [00:31<00:09, 17.21batch/s]Evaluating:  76%|███████▌  | 523/687 [00:31<00:09, 17.21batch/s]Evaluating:  76%|███████▋  | 525/687 [00:31<00:09, 17.19batch/s]Evaluating:  77%|███████▋  | 527/687 [00:31<00:09, 17.08batch/s]Evaluating:  77%|███████▋  | 529/687 [00:32<00:09, 17.13batch/s]Evaluating:  77%|███████▋  | 531/687 [00:32<00:09, 17.15batch/s]Evaluating:  78%|███████▊  | 533/687 [00:32<00:08, 17.13batch/s]Evaluating:  78%|███████▊  | 535/687 [00:32<00:08, 17.14batch/s]Evaluating:  78%|███████▊  | 537/687 [00:32<00:08, 17.17batch/s]Evaluating:  78%|███████▊  | 539/687 [00:32<00:08, 17.19batch/s]Evaluating:  79%|███████▊  | 541/687 [00:32<00:08, 17.19batch/s]Evaluating:  79%|███████▉  | 543/687 [00:32<00:08, 17.19batch/s]Evaluating:  79%|███████▉  | 545/687 [00:33<00:08, 17.20batch/s]Evaluating:  80%|███████▉  | 547/687 [00:33<00:08, 17.20batch/s]Evaluating:  80%|███████▉  | 549/687 [00:33<00:08, 17.17batch/s]Evaluating:  80%|████████  | 551/687 [00:33<00:07, 17.19batch/s]Evaluating:  80%|████████  | 553/687 [00:33<00:07, 17.18batch/s]Evaluating:  81%|████████  | 555/687 [00:33<00:07, 17.16batch/s]Evaluating:  81%|████████  | 557/687 [00:33<00:07, 17.15batch/s]Evaluating:  81%|████████▏ | 559/687 [00:33<00:07, 17.13batch/s]Evaluating:  82%|████████▏ | 561/687 [00:33<00:07, 17.17batch/s]Evaluating:  82%|████████▏ | 563/687 [00:34<00:07, 17.17batch/s]Evaluating:  82%|████████▏ | 565/687 [00:34<00:07, 17.19batch/s]Evaluating:  83%|████████▎ | 567/687 [00:34<00:06, 17.17batch/s]Evaluating:  83%|████████▎ | 569/687 [00:34<00:06, 17.20batch/s]Evaluating:  83%|████████▎ | 571/687 [00:34<00:06, 17.19batch/s]Evaluating:  83%|████████▎ | 573/687 [00:34<00:06, 17.20batch/s]Evaluating:  84%|████████▎ | 575/687 [00:34<00:06, 17.19batch/s]Evaluating:  84%|████████▍ | 577/687 [00:34<00:06, 17.19batch/s]Evaluating:  84%|████████▍ | 579/687 [00:34<00:06, 17.19batch/s]Evaluating:  85%|████████▍ | 581/687 [00:35<00:06, 17.17batch/s]Evaluating:  85%|████████▍ | 583/687 [00:35<00:06, 17.19batch/s]Evaluating:  85%|████████▌ | 585/687 [00:35<00:05, 17.21batch/s]Evaluating:  85%|████████▌ | 587/687 [00:35<00:05, 17.20batch/s]Evaluating:  86%|████████▌ | 589/687 [00:35<00:05, 17.20batch/s]Evaluating:  86%|████████▌ | 591/687 [00:35<00:05, 17.16batch/s]Evaluating:  86%|████████▋ | 593/687 [00:35<00:05, 17.19batch/s]Evaluating:  87%|████████▋ | 595/687 [00:35<00:05, 17.20batch/s]Evaluating:  87%|████████▋ | 597/687 [00:36<00:05, 17.17batch/s]Evaluating:  87%|████████▋ | 599/687 [00:36<00:05, 17.15batch/s]Evaluating:  87%|████████▋ | 601/687 [00:36<00:05, 17.16batch/s]Evaluating:  88%|████████▊ | 603/687 [00:36<00:04, 17.17batch/s]Evaluating:  88%|████████▊ | 605/687 [00:36<00:04, 17.15batch/s]Evaluating:  88%|████████▊ | 607/687 [00:36<00:04, 17.19batch/s]Evaluating:  89%|████████▊ | 609/687 [00:36<00:04, 17.21batch/s]Evaluating:  89%|████████▉ | 611/687 [00:36<00:04, 17.21batch/s]Evaluating:  89%|████████▉ | 613/687 [00:36<00:04, 17.21batch/s]Evaluating:  90%|████████▉ | 615/687 [00:37<00:04, 17.20batch/s]Evaluating:  90%|████████▉ | 617/687 [00:37<00:04, 17.23batch/s]Evaluating:  90%|█████████ | 619/687 [00:37<00:03, 17.21batch/s]Evaluating:  90%|█████████ | 621/687 [00:37<00:03, 17.19batch/s]Evaluating:  91%|█████████ | 623/687 [00:37<00:03, 17.15batch/s]Evaluating:  91%|█████████ | 625/687 [00:37<00:03, 17.21batch/s]Evaluating:  91%|█████████▏| 627/687 [00:37<00:03, 17.20batch/s]Evaluating:  92%|█████████▏| 629/687 [00:37<00:03, 17.19batch/s]Evaluating:  92%|█████████▏| 631/687 [00:38<00:03, 17.20batch/s]Evaluating:  92%|█████████▏| 633/687 [00:38<00:03, 17.24batch/s]Evaluating:  92%|█████████▏| 635/687 [00:38<00:03, 17.25batch/s]Evaluating:  93%|█████████▎| 637/687 [00:38<00:02, 17.21batch/s]Evaluating:  93%|█████████▎| 639/687 [00:38<00:02, 17.18batch/s]Evaluating:  93%|█████████▎| 641/687 [00:38<00:02, 17.18batch/s]Evaluating:  94%|█████████▎| 643/687 [00:38<00:02, 17.21batch/s]Evaluating:  94%|█████████▍| 645/687 [00:38<00:02, 17.19batch/s]Evaluating:  94%|█████████▍| 647/687 [00:38<00:02, 17.21batch/s]Evaluating:  94%|█████████▍| 649/687 [00:39<00:02, 17.22batch/s]Evaluating:  95%|█████████▍| 651/687 [00:39<00:02, 17.21batch/s]Evaluating:  95%|█████████▌| 653/687 [00:39<00:01, 17.21batch/s]Evaluating:  95%|█████████▌| 655/687 [00:39<00:01, 17.23batch/s]Evaluating:  96%|█████████▌| 657/687 [00:39<00:01, 17.22batch/s]Evaluating:  96%|█████████▌| 659/687 [00:39<00:01, 17.21batch/s]Evaluating:  96%|█████████▌| 661/687 [00:39<00:01, 17.19batch/s]Evaluating:  97%|█████████▋| 663/687 [00:39<00:01, 17.22batch/s]Evaluating:  97%|█████████▋| 665/687 [00:39<00:01, 17.22batch/s]Evaluating:  97%|█████████▋| 667/687 [00:40<00:01, 17.22batch/s]Evaluating:  97%|█████████▋| 669/687 [00:40<00:01, 17.20batch/s]Evaluating:  98%|█████████▊| 671/687 [00:40<00:00, 17.24batch/s]Evaluating:  98%|█████████▊| 673/687 [00:40<00:00, 17.22batch/s]Evaluating:  98%|█████████▊| 675/687 [00:40<00:00, 17.18batch/s]Evaluating:  99%|█████████▊| 677/687 [00:40<00:00, 17.19batch/s]Evaluating:  99%|█████████▉| 679/687 [00:40<00:00, 17.23batch/s]Evaluating:  99%|█████████▉| 681/687 [00:40<00:00, 17.23batch/s]Evaluating:  99%|█████████▉| 683/687 [00:41<00:00, 17.21batch/s]Evaluating: 100%|█████████▉| 685/687 [00:41<00:00, 17.22batch/s]Evaluating: 100%|██████████| 687/687 [00:41<00:00, 17.33batch/s]Evaluating: 100%|██████████| 687/687 [00:41<00:00, 16.60batch/s]
Top-1 Accuracy: 0.9945860
Top-5 Accuracy: 0.9993176
Top-1 Error Rate: 0.0054140
Top-5 Error Rate: 0.0006824
Parameter numbers: 21855214
GPU INFO.....
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  96029 KiB | 375212 KiB |   2581 GiB |   2580 GiB |
|       from large pool |  89088 KiB | 368192 KiB |   2557 GiB |   2557 GiB |
|       from small pool |   6941 KiB |  12772 KiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  96029 KiB | 375212 KiB |   2581 GiB |   2580 GiB |
|       from large pool |  89088 KiB | 368192 KiB |   2557 GiB |   2557 GiB |
|       from small pool |   6941 KiB |  12772 KiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  94312 KiB | 373495 KiB |   2581 GiB |   2580 GiB |
|       from large pool |  87408 KiB | 366512 KiB |   2557 GiB |   2557 GiB |
|       from small pool |   6904 KiB |  12701 KiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 563200 KiB | 563200 KiB | 563200 KiB |      0 B   |
|       from large pool | 548864 KiB | 548864 KiB | 548864 KiB |      0 B   |
|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14562 KiB | 145044 KiB |   2272 GiB |   2272 GiB |
|       from large pool |  13312 KiB | 143808 KiB |   2248 GiB |   2248 GiB |
|       from small pool |   1250 KiB |   6272 KiB |     23 GiB |     23 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     324    |     636    |  178570    |  178246    |
|       from large pool |      20    |      38    |  102402    |  102382    |
|       from small pool |     304    |     598    |   76168    |   75864    |
|---------------------------------------------------------------------------|
| Active allocs         |     324    |     636    |  178570    |  178246    |
|       from large pool |      20    |      38    |  102402    |  102382    |
|       from small pool |     304    |     598    |   76168    |   75864    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      20    |      20    |      20    |       0    |
|       from large pool |      13    |      13    |      13    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       5    |      13    |  106166    |  106161    |
|       from large pool |       2    |       7    |   69413    |   69411    |
|       from small pool |       3    |       7    |   36753    |   36750    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
